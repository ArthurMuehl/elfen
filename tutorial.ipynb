{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from datasets) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from datasets) (3.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from datasets) (0.24.5)\n",
      "Requirement already satisfied: packaging in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from aiohttp->datasets) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import datasets\n",
    "\n",
    "import src.extractor as ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "This package assumes and is optimized for 'tabular' text dataset, i.e. datasets with a text column with several items/instances.\n",
    "The default text column name is `text`. To change that, change the config as specified below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset('Multilingual-Perspectivist-NLU/EPIC')\n",
    "df = pl.from_pandas(dataset[\"train\"].to_pandas())[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the extractor with to extract all currently supported base level features. The specification can be found in `src/config.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = ex.Extractor(data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of all features of the default config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting raw_sequence_length...\n",
      "Extracting n_tokens...\n",
      "Extracting n_sentences...\n",
      "Extracting n_tokens_per_sentence...\n",
      "Extracting n_characters...\n",
      "Extracting avg_word_length...\n",
      "Extracting n_types...\n",
      "Extracting n_long_words...\n",
      "Extracting n_lemmas...\n",
      "Extracting sentiment_score...\n",
      "Extracting n_negative_sentiment...\n",
      "Extracting n_positive_sentiment...\n",
      "Extracting avg_valence...\n",
      "Extracting n_low_valence...\n",
      "Extracting n_high_valence...\n",
      "Extracting avg_arousal...\n",
      "Extracting n_low_arousal...\n",
      "Extracting n_high_arousal...\n",
      "Extracting avg_dominance...\n",
      "Extracting n_low_dominance...\n",
      "Extracting n_high_dominance...\n",
      "Extracting avg_emotion_intensity...\n",
      "Extracting n_low_intensity...\n",
      "Extracting n_high_intensity...\n",
      "Extracting compressibility...\n",
      "Extracting entropy...\n",
      "Extracting lemma_token_ratio...\n",
      "Extracting ttr...\n",
      "Extracting rttr...\n",
      "Extracting cttr...\n",
      "Extracting herdan_c...\n",
      "Extracting summer_index...\n",
      "Extracting dougast_u...\n",
      "Extracting maas_index...\n",
      "Extracting n_hapax_legomena...\n",
      "Extracting n_hapax_legomena_token_ratio...\n",
      "Extracting n_hapax_legomena_type_ratio...\n",
      "Extracting lexical_density...\n",
      "Extracting n_hapax_dislegomena...\n",
      "Extracting n_hapax_dislegomena_token_ratio...\n",
      "Extracting n_hapax_dislegomena_type_ratio...\n",
      "Extracting sichel_s...\n",
      "Extracting giroud_index...\n",
      "Extracting mtld...\n",
      "Extracting hdd...\n",
      "Extracting mattr...\n",
      "Extracting msttr...\n",
      "Extracting n_lexical_tokens...\n",
      "Extracting pos_variability...\n",
      "Extracting n_per_pos...\n",
      "Extracting avg_concreteness...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting n_low_concreteness...\n",
      "Extracting n_high_concreteness...\n",
      "Extracting avg_aoa...\n",
      "Extracting n_low_aoa...\n",
      "Extracting n_high_aoa...\n",
      "Extracting avg_prevalence...\n",
      "Extracting n_low_prevalence...\n",
      "Extracting n_high_prevalence...\n",
      "Extracting n_syllables...\n",
      "Extracting n_monosyllables...\n",
      "Extracting n_polysyllables...\n",
      "Extracting flesch_reading_ease...\n",
      "Extracting flesch_kincaid_grade...\n",
      "Extracting gunning_fog...\n",
      "Extracting ari...\n",
      "Extracting smog...\n",
      "Extracting cli...\n",
      "Extracting lix...\n",
      "Extracting rix...\n",
      "Extracting n_lemmas...\n",
      "Extracting n_hedges...\n",
      "Extracting avg_num_synsets...\n",
      "Extracting avg_num_synsets_per_pos...\n",
      "Extracting n_low_synsets...\n",
      "Extracting n_high_synsets...\n",
      "Extracting n_entities...\n",
      "Extracting n_entities_token_ratio...\n",
      "Extracting n_entities_sentence_ratio...\n",
      "Extracting n_per_entity_type...\n"
     ]
    }
   ],
   "source": [
    "df1 = extractor.extract_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add ratios, just append the name of the base level feature + ratio name (find them in `src/ratios.py`). Edit the default config as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ex.CONFIG_ALL\n",
    "# base feature without any additional configutation; use defaults\n",
    "config[\"features\"][\"emotion\"][\"n_low_valence_token_ratio\"] = {}\n",
    "# base feature with additional configuration\n",
    "config[\"features\"][\"emotion\"][\"n_low_valence_token_ratio\"] = {\"threshold\": 0.5,\n",
    "                                                              \"lexicon\": \"vad_nrc\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the text column has a different name this can be addressed either in the input data frame by renaming the column or by specifying the text column name in the config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"text_column\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with the edited config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting raw_sequence_length...\n",
      "Extracting n_tokens...\n",
      "Extracting n_sentences...\n",
      "Extracting n_tokens_per_sentence...\n",
      "Extracting n_characters...\n",
      "Extracting avg_word_length...\n",
      "Extracting n_types...\n",
      "Extracting n_long_words...\n",
      "Extracting n_lemmas...\n",
      "Extracting sentiment_score...\n",
      "Extracting n_negative_sentiment...\n",
      "Extracting n_positive_sentiment...\n",
      "Extracting avg_valence...\n",
      "Extracting n_low_valence...\n",
      "Extracting n_high_valence...\n",
      "Extracting avg_arousal...\n",
      "Extracting n_low_arousal...\n",
      "Extracting n_high_arousal...\n",
      "Extracting avg_dominance...\n",
      "Extracting n_low_dominance...\n",
      "Extracting n_high_dominance...\n",
      "Extracting avg_emotion_intensity...\n",
      "Extracting n_low_intensity...\n",
      "Extracting n_high_intensity...\n",
      "Extracting n_low_valence_token_ratio...\n",
      "Extracting compressibility...\n",
      "Extracting entropy...\n",
      "Extracting lemma_token_ratio...\n",
      "Extracting ttr...\n",
      "Extracting rttr...\n",
      "Extracting cttr...\n",
      "Extracting herdan_c...\n",
      "Extracting summer_index...\n",
      "Extracting dougast_u...\n",
      "Extracting maas_index...\n",
      "Extracting n_hapax_legomena...\n",
      "Extracting n_hapax_legomena_token_ratio...\n",
      "Extracting n_hapax_legomena_type_ratio...\n",
      "Extracting lexical_density...\n",
      "Extracting n_hapax_dislegomena...\n",
      "Extracting n_hapax_dislegomena_token_ratio...\n",
      "Extracting n_hapax_dislegomena_type_ratio...\n",
      "Extracting sichel_s...\n",
      "Extracting giroud_index...\n",
      "Extracting mtld...\n",
      "Extracting hdd...\n",
      "Extracting mattr...\n",
      "Extracting msttr...\n",
      "Extracting n_lexical_tokens...\n",
      "Extracting pos_variability...\n",
      "Extracting n_per_pos...\n",
      "Extracting avg_concreteness...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/mmm/.conda/envs/ling-features/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting n_low_concreteness...\n",
      "Extracting n_high_concreteness...\n",
      "Extracting avg_aoa...\n",
      "Extracting n_low_aoa...\n",
      "Extracting n_high_aoa...\n",
      "Extracting avg_prevalence...\n",
      "Extracting n_low_prevalence...\n",
      "Extracting n_high_prevalence...\n",
      "Extracting n_syllables...\n",
      "Extracting n_monosyllables...\n",
      "Extracting n_polysyllables...\n",
      "Extracting flesch_reading_ease...\n",
      "Extracting flesch_kincaid_grade...\n",
      "Extracting gunning_fog...\n",
      "Extracting ari...\n",
      "Extracting smog...\n",
      "Extracting cli...\n",
      "Extracting lix...\n",
      "Extracting rix...\n",
      "Extracting n_lemmas...\n",
      "Extracting n_hedges...\n",
      "Extracting avg_num_synsets...\n",
      "Extracting avg_num_synsets_per_pos...\n",
      "Extracting n_low_synsets...\n",
      "Extracting n_high_synsets...\n",
      "Extracting n_entities...\n",
      "Extracting n_entities_token_ratio...\n",
      "Extracting n_entities_sentence_ratio...\n",
      "Extracting n_per_entity_type...\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset('Multilingual-Perspectivist-NLU/EPIC')\n",
    "df = pl.from_pandas(dataset[\"train\"].to_pandas())[:100]\n",
    "\n",
    "extractor = ex.Extractor(data=df, config=config)\n",
    "df2 = extractor.extract_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 166)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1.columns), len(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ColumnNotFoundError",
     "evalue": "n_low_valence_token_ratio",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mColumnNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_low_valence_token_ratio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/.conda/envs/ling-features/lib/python3.12/site-packages/polars/dataframe/frame.py:8685\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *exprs, **named_exprs)\u001b[0m\n\u001b[1;32m   8585\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\n\u001b[1;32m   8586\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mexprs: IntoExpr \u001b[38;5;241m|\u001b[39m Iterable[IntoExpr], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnamed_exprs: IntoExpr\n\u001b[1;32m   8587\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   8588\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   8589\u001b[0m \u001b[38;5;124;03m    Select columns from this DataFrame.\u001b[39;00m\n\u001b[1;32m   8590\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8683\u001b[0m \u001b[38;5;124;03m    └──────────────┘\u001b[39;00m\n\u001b[1;32m   8684\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 8685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexprs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnamed_exprs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/ling-features/lib/python3.12/site-packages/polars/lazyframe/frame.py:2026\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[0;32m-> 2026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mColumnNotFoundError\u001b[0m: n_low_valence_token_ratio"
     ]
    }
   ],
   "source": [
    "df1.select(\"n_low_valence_token_ratio\").head() # as expected, this will fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>n_low_valence_token_ratio</th></tr><tr><td>f64</td></tr></thead><tbody><tr><td>0.294118</td></tr><tr><td>0.294118</td></tr><tr><td>0.294118</td></tr><tr><td>0.294118</td></tr><tr><td>0.294118</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1)\n",
       "┌───────────────────────────┐\n",
       "│ n_low_valence_token_ratio │\n",
       "│ ---                       │\n",
       "│ f64                       │\n",
       "╞═══════════════════════════╡\n",
       "│ 0.294118                  │\n",
       "│ 0.294118                  │\n",
       "│ 0.294118                  │\n",
       "│ 0.294118                  │\n",
       "│ 0.294118                  │\n",
       "└───────────────────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.select(\"n_low_valence_token_ratio\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ling-features",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
